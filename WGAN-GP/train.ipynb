{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Train a WGAN-GP on MNIST.\n",
    "\"\"\"\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import torchvision.utils as vutils\n",
    "from model import Critic, Generator, initialize_weights\n",
    "from utils import gradient_penalty\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 100\n",
    "FEATURES_CRITIC = 16\n",
    "FEATURES_GEN = 16\n",
    "\n",
    "#According to paper\n",
    "CRITIC_ITERS = 5\n",
    "LAMBDA = 10\n",
    "\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.5 for _ in range(CHANNELS_IMG)],[ 0.5 for _ in range(CHANNELS_IMG)]),\n",
    "\n",
    "]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, transform=transforms, download=True)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "critic = Critic(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "\n",
    "\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "\n",
    "img_list = []\n",
    "\n",
    "gen.train()\n",
    "critic.train()\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (imgs, _) in enumerate(loader):\n",
    "        iters += 1\n",
    "        imgs = imgs.to(device) #real\n",
    "        curr_batch_size = imgs.shape[0]\n",
    "\n",
    "        #From paper train critic 5 iters for 1 iter of generator\n",
    "        #Train critic: max E[critic(real)] - E[critic(fake)] i.e min -(E[critic(real)] - E[critic(fake)])\n",
    "\n",
    "\n",
    "        noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1).to(device)\n",
    "        # Train critic\n",
    "        fake = gen(noise)\n",
    "\n",
    "        real_outputs = critic(imgs).reshape(-1)\n",
    "        fake_outputs = critic(fake.detach()).reshape(-1) # detach for reuse in generator\n",
    "        gp = gradient_penalty(critic, imgs, fake, device= device)\n",
    "        critic_loss = ( \n",
    "            -(torch.mean(real_outputs) - torch.mean(fake_outputs)) + LAMBDA * gp\n",
    "            )\n",
    "        critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        opt_critic.step()\n",
    "        # Train Generator\n",
    "        \n",
    "        \n",
    "        # Train Generator: max E[critic(gen_fake)] i.e min -E[critic(gen_fake)]\n",
    "        gen_fake = critic(fake).reshape(-1)\n",
    "        gen_loss = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "\n",
    "        if (iters % 200 == 0) or ((epoch == NUM_EPOCHS-1) and (i == len(loader)-1)):\n",
    "            with torch.no_grad():\n",
    "                faker = gen(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(faker, padding=2, normalize=True))\n",
    "\n",
    "\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"Epoch: {}/{}\".format(epoch, NUM_EPOCHS))\n",
    "            print(\"Critic loss: {}\".format(d_loss))\n",
    "            print(\"Generator loss: {}\".format(g_loss))\n",
    "            # print(\"Real outputs: {}\".format(real_outputs))\n",
    "            # print(\"Fake outputs: {}\".format(fake_outputs))\n",
    "            # print(\"Real labels: {}\".format(real_labels))\n",
    "            # print(\"Fake labels: {}\".format(fake_labels))\n",
    "            # print(\"Generator output: {}\".format(gen(noise)))\n",
    "            # print(\"Critic output: {}\".format(critic(imgs)))\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
